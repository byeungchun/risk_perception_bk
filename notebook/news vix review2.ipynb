{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile_news = os.path.join(os.path.expanduser('~'), 'Downloads', 'archive.zip')\n",
    "decompress_dir = os.path.join(os.path.expanduser('~'), 'Downloads', 'news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists. skip decompressing\n"
     ]
    }
   ],
   "source": [
    "# extract zipfile to 'news' folder in Download folder\n",
    "with ZipFile(zipfile_news, 'r') as zipObj:\n",
    "    if os.path.exists(decompress_dir):\n",
    "        print('Folder already exists. skip decompressing')\n",
    "    else:\n",
    "        zipObj.extractall(decompress_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst_newsjson_dir = glob.glob(r'C:\\Users\\byeun\\Downloads\\news\\*')\n",
    "\n",
    "# high spec PC on my desk\n",
    "lst_newsjson_dir = glob.glob(r'D:\\data\\kaggle_news\\*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    return re.compile('\\w+').findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57802/57802 [16:26<00:00, 58.57it/s]\n",
      "100%|██████████| 64592/64592 [17:39<00:00, 60.94it/s]\n",
      "100%|██████████| 57456/57456 [15:24<00:00, 62.13it/s]\n",
      "100%|██████████| 63245/63245 [17:06<00:00, 61.62it/s] \n",
      "100%|██████████| 63147/63147 [17:09<00:00, 61.31it/s]\n"
     ]
    }
   ],
   "source": [
    "dic_all_news = {}\n",
    "dic_all_thread = {}\n",
    "dic_all_social = {}\n",
    "dic_all_entity = {}\n",
    "dic_all_news_text = {}\n",
    "\n",
    "for newsjson_dir in lst_newsjson_dir:\n",
    "    lst_jsonfile = glob.glob(newsjson_dir + r'\\*.json')\n",
    "\n",
    "    for i, jsonfile in enumerate(tqdm(lst_jsonfile)):\n",
    "        \n",
    "        dic_news = json.load(open(jsonfile, 'rt', encoding='utf-8'))\n",
    "        uuid = dic_news.pop('uuid')\n",
    "        dic_all_news[uuid] = dic_news\n",
    "        \n",
    "        dic_thread = dic_news.pop('thread')\n",
    "      \n",
    "        news_text = dic_news.pop('text')\n",
    "        news_word = get_words(news_text)\n",
    "        news_word_cnt = len(news_word)\n",
    "        \n",
    "        dic_news['word_cnt'] = news_word_cnt\n",
    "\n",
    "        dic_all_social[uuid] = dic_thread.pop('social')\n",
    "        dic_all_thread[uuid] = dic_thread\n",
    "        dic_all_entity[uuid] = dic_news.pop('entities')\n",
    "\n",
    "        dic_all_news[uuid] = dic_news\n",
    "\n",
    "        dic_all_news_text[uuid] = {'text': news_text} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306188"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic_all_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dic_all_news to pickle file\n",
    "processed_dir = r'D:\\data\\kaggle_news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dic_all_thread, dic_all_social, dic_all_entity, dic_all_news_text to pickle\n",
    "\n",
    "pickle.dump(dic_all_news, open('dic_all_news.pkl', 'wb'))\n",
    "pickle.dump(dic_all_thread, open('dic_all_thread.pkl', 'wb'))\n",
    "pickle.dump(dic_all_social, open('dic_all_social.pkl', 'wb'))\n",
    "pickle.dump(dic_all_entity, open('dic_all_entity.pkl', 'wb'))\n",
    "pickle.dump(dic_all_news_text, open('dic_all_news_text.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News publishment summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_uuid_date = {}\n",
    "lst_publish_date = []\n",
    "for uuid, dic_news in dic_all_news.items():\n",
    "    dic_uuid_date[uuid] = pd.to_datetime(dic_news['published']).strftime('%Y-%m-%d')\n",
    "    lst_publish_date.append([dic_news['published'], dic_news['language']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_publish_date = pd.DataFrame(lst_publish_date)\n",
    "ts_publish_date.columns = ['pubdate','language']\n",
    "ts_publish_date['count'] = 1\n",
    "\n",
    "ts_publish_date.set_index(pd.PeriodIndex(ts_publish_date['pubdate'],freq='D'), inplace=True)\n",
    "\n",
    "# drop pubdate column\n",
    "ts_publish_date.drop('pubdate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of news by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubdate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01</th>\n",
       "      <td>57704</td>\n",
       "      <td>57704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         language  count\n",
       "pubdate                 \n",
       "2017-12        75     75\n",
       "2018-01     57704  57704\n",
       "2018-02        23     23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert timestamp to date format\n",
    "ts_publish_date.resample('M').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of news by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "english    57802\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_publish_date['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social media summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_social_cnt = {}\n",
    "for uuid, dic_social in dic_all_social.items():\n",
    "    pubdate = dic_uuid_date[uuid]\n",
    "    for sns, dic_event in dic_social.items():\n",
    "        for event_type, event_cnt in dic_event.items():\n",
    "\n",
    "            if not dic_social_cnt.get(pubdate):\n",
    "                dic_social_cnt[pubdate] = {}\n",
    "\n",
    "            if not dic_social_cnt[pubdate].get(sns):\n",
    "                dic_social_cnt[pubdate][sns] = {}\n",
    "            \n",
    "            if not dic_social_cnt[pubdate][sns].get(event_type):\n",
    "                dic_social_cnt[pubdate][sns][event_type] = 0\n",
    "            \n",
    "            dic_social_cnt[pubdate][sns][event_type] += event_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_df_social = []\n",
    "for pubdate, x in dic_social_cnt.items():\n",
    "    df = pd.DataFrame(x)\n",
    "    df['pubdate'] = pubdate\n",
    "    lst_df_social.append(df)\n",
    "\n",
    "df_social = pd.concat(lst_df_social)\n",
    "df_social.index.name = 'event_type'\n",
    "df_social.reset_index(inplace=True)\n",
    "df_social.set_index('pubdate', inplace=True, drop=True)\n",
    "df_social.index = pd.PeriodIndex(df_social.index, freq='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_type</th>\n",
       "      <th>gplus</th>\n",
       "      <th>pinterest</th>\n",
       "      <th>vk</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>facebook</th>\n",
       "      <th>stumbledupon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubdate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>comments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>likes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>shares</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-08</th>\n",
       "      <td>shares</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-08</th>\n",
       "      <td>comments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-08</th>\n",
       "      <td>likes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-10</th>\n",
       "      <td>comments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-10</th>\n",
       "      <td>likes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-10</th>\n",
       "      <td>shares</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>likes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           event_type  gplus  pinterest   vk  linkedin  facebook  stumbledupon\n",
       "pubdate                                                                       \n",
       "2017-12-07   comments    NaN        NaN  NaN       NaN         0           NaN\n",
       "2017-12-07      likes    NaN        NaN  NaN       NaN         0           NaN\n",
       "2017-12-07     shares    0.0        0.0  0.0       0.0         0           0.0\n",
       "2017-12-08     shares    0.0        0.0  0.0       0.0         0           0.0\n",
       "2017-12-08   comments    NaN        NaN  NaN       NaN         0           NaN\n",
       "2017-12-08      likes    NaN        NaN  NaN       NaN         0           NaN\n",
       "2017-12-10   comments    NaN        NaN  NaN       NaN         0           NaN\n",
       "2017-12-10      likes    NaN        NaN  NaN       NaN         0           NaN\n",
       "2017-12-10     shares    0.0        0.0  0.0       0.0         0           0.0\n",
       "2017-12-13      likes    NaN        NaN  NaN       NaN         0           NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_social.sort_index().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of shares by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gplus</th>\n",
       "      <th>pinterest</th>\n",
       "      <th>vk</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>facebook</th>\n",
       "      <th>stumbledupon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubdate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-04/2017-12-10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-11/2017-12-17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-18/2017-12-24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-25/2017-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01/2018-01-07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11129.0</td>\n",
       "      <td>95653</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08/2018-01-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17916.0</td>\n",
       "      <td>121651</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-15/2018-01-21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17728.0</td>\n",
       "      <td>102892</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-22/2018-01-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18063.0</td>\n",
       "      <td>129129</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-29/2018-02-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12879.0</td>\n",
       "      <td>62587</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       gplus  pinterest    vk  linkedin  facebook   \n",
       "pubdate                                                             \n",
       "2017-12-04/2017-12-10    0.0        0.0   0.0       0.0         0  \\\n",
       "2017-12-11/2017-12-17    0.0        0.0   0.0       0.0         0   \n",
       "2017-12-18/2017-12-24    0.0        0.0   0.0       0.0         0   \n",
       "2017-12-25/2017-12-31    0.0        0.0   0.0       0.0         0   \n",
       "2018-01-01/2018-01-07    0.0       54.0   7.0   11129.0     95653   \n",
       "2018-01-08/2018-01-14    0.0       89.0  14.0   17916.0    121651   \n",
       "2018-01-15/2018-01-21    0.0      122.0   5.0   17728.0    102892   \n",
       "2018-01-22/2018-01-28    0.0      115.0   5.0   18063.0    129129   \n",
       "2018-01-29/2018-02-04    0.0       99.0   2.0   12879.0     62587   \n",
       "\n",
       "                       stumbledupon  \n",
       "pubdate                              \n",
       "2017-12-04/2017-12-10           0.0  \n",
       "2017-12-11/2017-12-17           0.0  \n",
       "2017-12-18/2017-12-24           0.0  \n",
       "2017-12-25/2017-12-31           0.0  \n",
       "2018-01-01/2018-01-07           2.0  \n",
       "2018-01-08/2018-01-14           6.0  \n",
       "2018-01-15/2018-01-21          63.0  \n",
       "2018-01-22/2018-01-28           1.0  \n",
       "2018-01-29/2018-02-04           0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_social[df_social.event_type == 'shares'].resample('W').sum(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_full                                                  www.cnbc.com\n",
       "main_image            https://fm.cnbc.com/applications/cnbc.com/reso...\n",
       "site_section          http://www.cnbc.com/id/19746125/device/rss/rss...\n",
       "section_title                               Top News and Analysis (pro)\n",
       "url                   https://www.cnbc.com/2018/01/03/emerging-marke...\n",
       "country                                                              US\n",
       "domain_rank                                                       767.0\n",
       "title                 Emerging markets are set for an even bigger ra...\n",
       "performance_score                                                     0\n",
       "site                                                           cnbc.com\n",
       "participants_count                                                    0\n",
       "title_full                                                             \n",
       "spam_score                                                          0.0\n",
       "site_type                                                         blogs\n",
       "published                                 2018-01-03T15:00:00.000+02:00\n",
       "replies_count                                                         0\n",
       "uuid                           f86b78623d7a4412c76c1d80ed091184e2c29969\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thread = pd.DataFrame(dic_all_thread.values())\n",
    "df_thread.iloc[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "performance_score\n",
       "0     56933\n",
       "1       341\n",
       "2       151\n",
       "10      100\n",
       "3        89\n",
       "4        60\n",
       "5        41\n",
       "6        30\n",
       "8        20\n",
       "7        20\n",
       "9        17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thread.performance_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam_score\n",
       "0.000    39798\n",
       "0.001     1393\n",
       "0.002      729\n",
       "1.000      618\n",
       "0.003      485\n",
       "         ...  \n",
       "0.754        2\n",
       "0.549        1\n",
       "0.674        1\n",
       "0.395        1\n",
       "0.843        1\n",
       "Name: count, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thread.spam_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_type\n",
       "news     55714\n",
       "blogs     2088\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thread.site_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site\n",
       "reuters.com    37262\n",
       "cnbc.com       16019\n",
       "wsj.com         3412\n",
       "fortune.com     1109\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thread.site.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "US    57802\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thread.country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [x.keys() for x in dic_all_entity.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persons': [{'name': 'jia', 'sentiment': 'none'},\n",
       "  {'name': 'leshi', 'sentiment': 'none'},\n",
       "  {'name': 'jia yueting', 'sentiment': 'none'}],\n",
       " 'locations': [{'name': 'china', 'sentiment': 'none'},\n",
       "  {'name': 'sunac china', 'sentiment': 'none'},\n",
       "  {'name': 'leshi', 'sentiment': 'none'},\n",
       "  {'name': 'hong kong', 'sentiment': 'none'},\n",
       "  {'name': 'shenzhen', 'sentiment': 'none'}],\n",
       " 'organizations': [{'name': 'leshi internet', 'sentiment': 'negative'},\n",
       "  {'name': 'leeco', 'sentiment': 'negative'},\n",
       "  {'name': 'reuters staff', 'sentiment': 'none'},\n",
       "  {'name': 'leshi internet information & technology', 'sentiment': 'none'},\n",
       "  {'name': 'reuters', 'sentiment': 'none'}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_all_entity[uuid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
